{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logistic Regression from Scratch",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tf-JpYi0mH13",
        "colab_type": "text"
      },
      "source": [
        "# Logistic Regression from Scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0B9zbZ7el63G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFLr6RzvnBCO",
        "colab_type": "text"
      },
      "source": [
        "#### Necessary Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlwLfmUlmGSW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfowsJnxnErW",
        "colab_type": "text"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPfATNMynCtS",
        "colab_type": "code",
        "outputId": "d56c7e30-38ab-43dc-81cf-09c3b2363387",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "raw_data = pd.read_csv(\"amazon_baby_subset.csv\")\n",
        "raw_data.head(10)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>review</th>\n",
              "      <th>rating</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
              "      <td>All of my kids have cried non-stop when I trie...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
              "      <td>We wanted to get something to keep track of ou...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
              "      <td>My daughter had her 1st baby over a year ago. ...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Lamaze Peekaboo, I Love You</td>\n",
              "      <td>One of baby's first and favorite books, and it...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SoftPlay Peek-A-Boo Where's Elmo A Children's ...</td>\n",
              "      <td>Very cute interactive book! My son loves this ...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Our Baby Girl Memory Book</td>\n",
              "      <td>Beautiful book, I love it to record cherished ...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Hunnt&amp;reg; Falling Flowers and Birds Kids Nurs...</td>\n",
              "      <td>Try this out for a spring project !Easy ,fun a...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Blessed By Pope Benedict XVI Divine Mercy Full...</td>\n",
              "      <td>very nice Divine Mercy Pendant of Jesus now on...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Cloth Diaper Pins Stainless Steel Traditional ...</td>\n",
              "      <td>We bought the pins as my 6 year old Autistic s...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Cloth Diaper Pins Stainless Steel Traditional ...</td>\n",
              "      <td>It has been many years since we needed diaper ...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                name  ... sentiment\n",
              "0  Stop Pacifier Sucking without tears with Thumb...  ...         1\n",
              "1    Nature's Lullabies Second Year Sticker Calendar  ...         1\n",
              "2    Nature's Lullabies Second Year Sticker Calendar  ...         1\n",
              "3                        Lamaze Peekaboo, I Love You  ...         1\n",
              "4  SoftPlay Peek-A-Boo Where's Elmo A Children's ...  ...         1\n",
              "5                          Our Baby Girl Memory Book  ...         1\n",
              "6  Hunnt&reg; Falling Flowers and Birds Kids Nurs...  ...         1\n",
              "7  Blessed By Pope Benedict XVI Divine Mercy Full...  ...         1\n",
              "8  Cloth Diaper Pins Stainless Steel Traditional ...  ...         1\n",
              "9  Cloth Diaper Pins Stainless Steel Traditional ...  ...         1\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QieQr5TDoSC",
        "colab_type": "code",
        "outputId": "16f3a537-dd6a-4b01-a8dc-7d5c58d4b265",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "data = raw_data.fillna({'review':''})\n",
        "data.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>review</th>\n",
              "      <th>rating</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
              "      <td>All of my kids have cried non-stop when I trie...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
              "      <td>We wanted to get something to keep track of ou...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
              "      <td>My daughter had her 1st baby over a year ago. ...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Lamaze Peekaboo, I Love You</td>\n",
              "      <td>One of baby's first and favorite books, and it...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SoftPlay Peek-A-Boo Where's Elmo A Children's ...</td>\n",
              "      <td>Very cute interactive book! My son loves this ...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                name  ... sentiment\n",
              "0  Stop Pacifier Sucking without tears with Thumb...  ...         1\n",
              "1    Nature's Lullabies Second Year Sticker Calendar  ...         1\n",
              "2    Nature's Lullabies Second Year Sticker Calendar  ...         1\n",
              "3                        Lamaze Peekaboo, I Love You  ...         1\n",
              "4  SoftPlay Peek-A-Boo Where's Elmo A Children's ...  ...         1\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPhqM3I1nMUH",
        "colab_type": "code",
        "outputId": "9f60e716-3cd0-409e-93ff-b7a4aa2dac7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 53072 entries, 0 to 53071\n",
            "Data columns (total 4 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   name       52982 non-null  object\n",
            " 1   review     53072 non-null  object\n",
            " 2   rating     53072 non-null  int64 \n",
            " 3   sentiment  53072 non-null  int64 \n",
            "dtypes: int64(2), object(2)\n",
            "memory usage: 1.6+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXl9uX9fniwi",
        "colab_type": "code",
        "outputId": "db88613c-2850-4ffd-ced3-a65a0c2120f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "data.describe(include='all')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>review</th>\n",
              "      <th>rating</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>52982</td>\n",
              "      <td>53072</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>17021</td>\n",
              "      <td>52831</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>Vulli Sophie the Giraffe Teether</td>\n",
              "      <td></td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>207</td>\n",
              "      <td>241</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.097490</td>\n",
              "      <td>0.001620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.730509</td>\n",
              "      <td>1.000008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    name review        rating     sentiment\n",
              "count                              52982  53072  53072.000000  53072.000000\n",
              "unique                             17021  52831           NaN           NaN\n",
              "top     Vulli Sophie the Giraffe Teether                  NaN           NaN\n",
              "freq                                 207    241           NaN           NaN\n",
              "mean                                 NaN    NaN      3.097490      0.001620\n",
              "std                                  NaN    NaN      1.730509      1.000008\n",
              "min                                  NaN    NaN      1.000000     -1.000000\n",
              "25%                                  NaN    NaN      1.000000     -1.000000\n",
              "50%                                  NaN    NaN      4.000000      1.000000\n",
              "75%                                  NaN    NaN      5.000000      1.000000\n",
              "max                                  NaN    NaN      5.000000      1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upvLCOBQn3GB",
        "colab_type": "code",
        "outputId": "980b3a9e-91c4-4e48-ebc6-83c89527d330",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "data['sentiment'].value_counts()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 1    26579\n",
              "-1    26493\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsxiIfacisCV",
        "colab_type": "code",
        "outputId": "c0b52e14-6428-4913-82fe-803e08e579d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "sns.countplot(x='sentiment', data=data, palette='hls')\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-x7W0tQotxf",
        "colab_type": "text"
      },
      "source": [
        "#### Remove punctuation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qd9gNdzconNT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_punctuation(text):\n",
        "    import string\n",
        "    return str(text).translate(str.maketrans('', '', string.punctuation))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MP1N3sIEo2SS",
        "colab_type": "code",
        "outputId": "75137f76-d113-4317-ba71-4f18f3bbb5f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "data['review_clean'] = data['review'].apply(remove_punctuation)\n",
        "data[['review', 'review_clean']].head(10)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>review_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>All of my kids have cried non-stop when I trie...</td>\n",
              "      <td>All of my kids have cried nonstop when I tried...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>We wanted to get something to keep track of ou...</td>\n",
              "      <td>We wanted to get something to keep track of ou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>My daughter had her 1st baby over a year ago. ...</td>\n",
              "      <td>My daughter had her 1st baby over a year ago S...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>One of baby's first and favorite books, and it...</td>\n",
              "      <td>One of babys first and favorite books and it i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Very cute interactive book! My son loves this ...</td>\n",
              "      <td>Very cute interactive book My son loves this b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Beautiful book, I love it to record cherished ...</td>\n",
              "      <td>Beautiful book I love it to record cherished t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Try this out for a spring project !Easy ,fun a...</td>\n",
              "      <td>Try this out for a spring project Easy fun and...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>very nice Divine Mercy Pendant of Jesus now on...</td>\n",
              "      <td>very nice Divine Mercy Pendant of Jesus now on...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>We bought the pins as my 6 year old Autistic s...</td>\n",
              "      <td>We bought the pins as my 6 year old Autistic s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>It has been many years since we needed diaper ...</td>\n",
              "      <td>It has been many years since we needed diaper ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review                                       review_clean\n",
              "0  All of my kids have cried non-stop when I trie...  All of my kids have cried nonstop when I tried...\n",
              "1  We wanted to get something to keep track of ou...  We wanted to get something to keep track of ou...\n",
              "2  My daughter had her 1st baby over a year ago. ...  My daughter had her 1st baby over a year ago S...\n",
              "3  One of baby's first and favorite books, and it...  One of babys first and favorite books and it i...\n",
              "4  Very cute interactive book! My son loves this ...  Very cute interactive book My son loves this b...\n",
              "5  Beautiful book, I love it to record cherished ...  Beautiful book I love it to record cherished t...\n",
              "6  Try this out for a spring project !Easy ,fun a...  Try this out for a spring project Easy fun and...\n",
              "7  very nice Divine Mercy Pendant of Jesus now on...  very nice Divine Mercy Pendant of Jesus now on...\n",
              "8  We bought the pins as my 6 year old Autistic s...  We bought the pins as my 6 year old Autistic s...\n",
              "9  It has been many years since we needed diaper ...  It has been many years since we needed diaper ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEB25RAGqA-G",
        "colab_type": "text"
      },
      "source": [
        "#### Compute word counts *(only for important_words)*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eu2htHA-oPYm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "with open('important_words.json', 'r') as f:\n",
        "    important_words = json.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IrlH8XGojtR",
        "colab_type": "code",
        "outputId": "2950dd1a-27b2-48a4-822a-4cc6760f57e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "print(sorted(important_words))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['able', 'actually', 'almost', 'also', 'amazon', 'another', 'anything', 'around', 'away', 'babies', 'baby', 'back', 'bad', 'bag', 'best', 'better', 'big', 'bit', 'bottle', 'bottles', 'bottom', 'bought', 'box', 'broke', 'buy', 'buying', 'came', 'car', 'chair', 'cheap', 'child', 'clean', 'come', 'comfortable', 'company', 'completely', 'could', 'cover', 'crib', 'cup', 'cute', 'daughter', 'day', 'design', 'diaper', 'different', 'difficult', 'disappointed', 'easily', 'easy', 'either', 'enough', 'even', 'every', 'find', 'first', 'fit', 'fits', 'found', 'gate', 'get', 'getting', 'give', 'go', 'going', 'good', 'got', 'great', 'happy', 'hard', 'head', 'high', 'hold', 'however', 'idea', 'instead', 'item', 'keep', 'kids', 'know', 'last', 'less', 'like', 'little', 'long', 'look', 'looking', 'looks', 'lot', 'love', 'loves', 'made', 'make', 'makes', 'many', 'maybe', 'milk', 'money', 'monitor', 'month', 'months', 'much', 'need', 'never', 'new', 'nice', 'night', 'old', 'one', 'open', 'ordered', 'part', 'perfect', 'picture', 'piece', 'place', 'plastic', 'play', 'pretty', 'price', 'problem', 'product', 'pump', 'purchase', 'purchased', 'put', 'quality', 'really', 'received', 'recommend', 'return', 'returned', 'reviews', 'right', 'room', 'said', 'say', 'seat', 'second', 'see', 'seems', 'set', 'side', 'since', 'size', 'small', 'soft', 'something', 'son', 'started', 'stay', 'still', 'stroller', 'sure', 'take', 'thing', 'think', 'though', 'thought', 'time', 'times', 'together', 'took', 'top', 'toy', 'tried', 'try', 'trying', 'tub', 'two', 'unit', 'us', 'use', 'used', 'using', 'want', 'wanted', 'waste', 'water', 'way', 'weeks', 'well', 'went', 'wish', 'without', 'won', 'work', 'worked', 'working', 'works', 'worth', 'would', 'year']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGmu1cCvpPQX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for word in important_words:\n",
        "    data[word] = data['review_clean'].apply(lambda s : s.split().count(word))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnldAL0sv6L0",
        "colab_type": "code",
        "outputId": "25bdc9ee-cd7b-43df-ca29-6aa49e96077e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        }
      },
      "source": [
        "data.head(10).iloc[:,5:]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>baby</th>\n",
              "      <th>one</th>\n",
              "      <th>great</th>\n",
              "      <th>love</th>\n",
              "      <th>use</th>\n",
              "      <th>would</th>\n",
              "      <th>like</th>\n",
              "      <th>easy</th>\n",
              "      <th>little</th>\n",
              "      <th>seat</th>\n",
              "      <th>old</th>\n",
              "      <th>well</th>\n",
              "      <th>get</th>\n",
              "      <th>also</th>\n",
              "      <th>really</th>\n",
              "      <th>son</th>\n",
              "      <th>time</th>\n",
              "      <th>bought</th>\n",
              "      <th>product</th>\n",
              "      <th>good</th>\n",
              "      <th>daughter</th>\n",
              "      <th>much</th>\n",
              "      <th>loves</th>\n",
              "      <th>stroller</th>\n",
              "      <th>put</th>\n",
              "      <th>months</th>\n",
              "      <th>car</th>\n",
              "      <th>still</th>\n",
              "      <th>back</th>\n",
              "      <th>used</th>\n",
              "      <th>recommend</th>\n",
              "      <th>first</th>\n",
              "      <th>even</th>\n",
              "      <th>perfect</th>\n",
              "      <th>nice</th>\n",
              "      <th>bag</th>\n",
              "      <th>two</th>\n",
              "      <th>using</th>\n",
              "      <th>got</th>\n",
              "      <th>fit</th>\n",
              "      <th>...</th>\n",
              "      <th>looks</th>\n",
              "      <th>second</th>\n",
              "      <th>piece</th>\n",
              "      <th>box</th>\n",
              "      <th>pretty</th>\n",
              "      <th>trying</th>\n",
              "      <th>difficult</th>\n",
              "      <th>together</th>\n",
              "      <th>though</th>\n",
              "      <th>give</th>\n",
              "      <th>started</th>\n",
              "      <th>anything</th>\n",
              "      <th>last</th>\n",
              "      <th>company</th>\n",
              "      <th>come</th>\n",
              "      <th>returned</th>\n",
              "      <th>maybe</th>\n",
              "      <th>took</th>\n",
              "      <th>broke</th>\n",
              "      <th>makes</th>\n",
              "      <th>stay</th>\n",
              "      <th>instead</th>\n",
              "      <th>idea</th>\n",
              "      <th>head</th>\n",
              "      <th>said</th>\n",
              "      <th>less</th>\n",
              "      <th>went</th>\n",
              "      <th>working</th>\n",
              "      <th>high</th>\n",
              "      <th>unit</th>\n",
              "      <th>seems</th>\n",
              "      <th>picture</th>\n",
              "      <th>completely</th>\n",
              "      <th>wish</th>\n",
              "      <th>buying</th>\n",
              "      <th>babies</th>\n",
              "      <th>won</th>\n",
              "      <th>tub</th>\n",
              "      <th>almost</th>\n",
              "      <th>either</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows  193 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   baby  one  great  love  use  would  ...  buying  babies  won  tub  almost  either\n",
              "0     0    0      1     0    0      0  ...       0       0    0    0       0       0\n",
              "1     0    0      0     0    0      0  ...       0       0    0    0       0       0\n",
              "2     1    0      0     0    0      0  ...       0       0    0    0       0       0\n",
              "3     0    0      0     0    0      0  ...       0       0    0    0       0       0\n",
              "4     0    0      1     0    0      0  ...       0       1    0    0       0       0\n",
              "5     0    0      1     1    0      0  ...       0       0    0    0       0       0\n",
              "6     0    0      0     0    0      0  ...       0       0    0    0       0       0\n",
              "7     0    0      0     0    0      0  ...       0       0    0    0       0       0\n",
              "8     0    1      0     0    1      0  ...       0       0    0    0       0       0\n",
              "9     0    1      0     0    0      0  ...       0       0    0    0       0       0\n",
              "\n",
              "[10 rows x 193 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0LcJjlKqeKB",
        "colab_type": "code",
        "outputId": "0100d75b-72f8-449a-8351-522fc618d273",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "source": [
        "data.describe()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>baby</th>\n",
              "      <th>one</th>\n",
              "      <th>great</th>\n",
              "      <th>love</th>\n",
              "      <th>use</th>\n",
              "      <th>would</th>\n",
              "      <th>like</th>\n",
              "      <th>easy</th>\n",
              "      <th>little</th>\n",
              "      <th>seat</th>\n",
              "      <th>old</th>\n",
              "      <th>well</th>\n",
              "      <th>get</th>\n",
              "      <th>also</th>\n",
              "      <th>really</th>\n",
              "      <th>son</th>\n",
              "      <th>time</th>\n",
              "      <th>bought</th>\n",
              "      <th>product</th>\n",
              "      <th>good</th>\n",
              "      <th>daughter</th>\n",
              "      <th>much</th>\n",
              "      <th>loves</th>\n",
              "      <th>stroller</th>\n",
              "      <th>put</th>\n",
              "      <th>months</th>\n",
              "      <th>car</th>\n",
              "      <th>still</th>\n",
              "      <th>back</th>\n",
              "      <th>used</th>\n",
              "      <th>recommend</th>\n",
              "      <th>first</th>\n",
              "      <th>even</th>\n",
              "      <th>perfect</th>\n",
              "      <th>nice</th>\n",
              "      <th>bag</th>\n",
              "      <th>two</th>\n",
              "      <th>using</th>\n",
              "      <th>...</th>\n",
              "      <th>looks</th>\n",
              "      <th>second</th>\n",
              "      <th>piece</th>\n",
              "      <th>box</th>\n",
              "      <th>pretty</th>\n",
              "      <th>trying</th>\n",
              "      <th>difficult</th>\n",
              "      <th>together</th>\n",
              "      <th>though</th>\n",
              "      <th>give</th>\n",
              "      <th>started</th>\n",
              "      <th>anything</th>\n",
              "      <th>last</th>\n",
              "      <th>company</th>\n",
              "      <th>come</th>\n",
              "      <th>returned</th>\n",
              "      <th>maybe</th>\n",
              "      <th>took</th>\n",
              "      <th>broke</th>\n",
              "      <th>makes</th>\n",
              "      <th>stay</th>\n",
              "      <th>instead</th>\n",
              "      <th>idea</th>\n",
              "      <th>head</th>\n",
              "      <th>said</th>\n",
              "      <th>less</th>\n",
              "      <th>went</th>\n",
              "      <th>working</th>\n",
              "      <th>high</th>\n",
              "      <th>unit</th>\n",
              "      <th>seems</th>\n",
              "      <th>picture</th>\n",
              "      <th>completely</th>\n",
              "      <th>wish</th>\n",
              "      <th>buying</th>\n",
              "      <th>babies</th>\n",
              "      <th>won</th>\n",
              "      <th>tub</th>\n",
              "      <th>almost</th>\n",
              "      <th>either</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "      <td>53072.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.097490</td>\n",
              "      <td>0.001620</td>\n",
              "      <td>0.352634</td>\n",
              "      <td>0.387003</td>\n",
              "      <td>0.219004</td>\n",
              "      <td>0.139603</td>\n",
              "      <td>0.278866</td>\n",
              "      <td>0.343345</td>\n",
              "      <td>0.264697</td>\n",
              "      <td>0.147837</td>\n",
              "      <td>0.184033</td>\n",
              "      <td>0.224035</td>\n",
              "      <td>0.186859</td>\n",
              "      <td>0.164362</td>\n",
              "      <td>0.244366</td>\n",
              "      <td>0.136701</td>\n",
              "      <td>0.175441</td>\n",
              "      <td>0.150399</td>\n",
              "      <td>0.190590</td>\n",
              "      <td>0.170636</td>\n",
              "      <td>0.217648</td>\n",
              "      <td>0.138359</td>\n",
              "      <td>0.121929</td>\n",
              "      <td>0.156354</td>\n",
              "      <td>0.078271</td>\n",
              "      <td>0.126074</td>\n",
              "      <td>0.148308</td>\n",
              "      <td>0.141657</td>\n",
              "      <td>0.111509</td>\n",
              "      <td>0.117312</td>\n",
              "      <td>0.160179</td>\n",
              "      <td>0.127902</td>\n",
              "      <td>0.103444</td>\n",
              "      <td>0.129993</td>\n",
              "      <td>0.149683</td>\n",
              "      <td>0.060427</td>\n",
              "      <td>0.077329</td>\n",
              "      <td>0.104594</td>\n",
              "      <td>0.113374</td>\n",
              "      <td>0.104179</td>\n",
              "      <td>...</td>\n",
              "      <td>0.049047</td>\n",
              "      <td>0.040643</td>\n",
              "      <td>0.035819</td>\n",
              "      <td>0.034990</td>\n",
              "      <td>0.050592</td>\n",
              "      <td>0.036479</td>\n",
              "      <td>0.035744</td>\n",
              "      <td>0.044524</td>\n",
              "      <td>0.050780</td>\n",
              "      <td>0.043620</td>\n",
              "      <td>0.040831</td>\n",
              "      <td>0.038099</td>\n",
              "      <td>0.039211</td>\n",
              "      <td>0.028904</td>\n",
              "      <td>0.044543</td>\n",
              "      <td>0.025041</td>\n",
              "      <td>0.020896</td>\n",
              "      <td>0.041039</td>\n",
              "      <td>0.027058</td>\n",
              "      <td>0.049763</td>\n",
              "      <td>0.033483</td>\n",
              "      <td>0.032654</td>\n",
              "      <td>0.030864</td>\n",
              "      <td>0.041924</td>\n",
              "      <td>0.036987</td>\n",
              "      <td>0.037477</td>\n",
              "      <td>0.036102</td>\n",
              "      <td>0.029036</td>\n",
              "      <td>0.041642</td>\n",
              "      <td>0.027774</td>\n",
              "      <td>0.045410</td>\n",
              "      <td>0.031203</td>\n",
              "      <td>0.029206</td>\n",
              "      <td>0.042037</td>\n",
              "      <td>0.035857</td>\n",
              "      <td>0.038212</td>\n",
              "      <td>0.000490</td>\n",
              "      <td>0.033690</td>\n",
              "      <td>0.039852</td>\n",
              "      <td>0.029846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.730509</td>\n",
              "      <td>1.000008</td>\n",
              "      <td>0.853823</td>\n",
              "      <td>0.805433</td>\n",
              "      <td>0.507811</td>\n",
              "      <td>0.448906</td>\n",
              "      <td>0.622370</td>\n",
              "      <td>0.726663</td>\n",
              "      <td>0.613662</td>\n",
              "      <td>0.438918</td>\n",
              "      <td>0.497465</td>\n",
              "      <td>1.024416</td>\n",
              "      <td>0.474519</td>\n",
              "      <td>0.442365</td>\n",
              "      <td>0.592578</td>\n",
              "      <td>0.428076</td>\n",
              "      <td>0.496591</td>\n",
              "      <td>0.475344</td>\n",
              "      <td>0.507693</td>\n",
              "      <td>0.427581</td>\n",
              "      <td>0.575792</td>\n",
              "      <td>0.405884</td>\n",
              "      <td>0.409374</td>\n",
              "      <td>0.439444</td>\n",
              "      <td>0.299197</td>\n",
              "      <td>0.810088</td>\n",
              "      <td>0.450017</td>\n",
              "      <td>0.437950</td>\n",
              "      <td>0.588466</td>\n",
              "      <td>0.382721</td>\n",
              "      <td>0.510398</td>\n",
              "      <td>0.400058</td>\n",
              "      <td>0.315183</td>\n",
              "      <td>0.400019</td>\n",
              "      <td>0.432580</td>\n",
              "      <td>0.259913</td>\n",
              "      <td>0.305855</td>\n",
              "      <td>0.628121</td>\n",
              "      <td>0.399044</td>\n",
              "      <td>0.357136</td>\n",
              "      <td>...</td>\n",
              "      <td>0.238600</td>\n",
              "      <td>0.224774</td>\n",
              "      <td>0.225927</td>\n",
              "      <td>0.230187</td>\n",
              "      <td>0.243053</td>\n",
              "      <td>0.204773</td>\n",
              "      <td>0.211197</td>\n",
              "      <td>0.250333</td>\n",
              "      <td>0.241458</td>\n",
              "      <td>0.218599</td>\n",
              "      <td>0.221276</td>\n",
              "      <td>0.208041</td>\n",
              "      <td>0.213690</td>\n",
              "      <td>0.206527</td>\n",
              "      <td>0.222557</td>\n",
              "      <td>0.164019</td>\n",
              "      <td>0.152351</td>\n",
              "      <td>0.216459</td>\n",
              "      <td>0.186763</td>\n",
              "      <td>0.235270</td>\n",
              "      <td>0.193032</td>\n",
              "      <td>0.186827</td>\n",
              "      <td>0.182079</td>\n",
              "      <td>0.271213</td>\n",
              "      <td>0.212318</td>\n",
              "      <td>0.211699</td>\n",
              "      <td>0.209389</td>\n",
              "      <td>0.195686</td>\n",
              "      <td>0.251542</td>\n",
              "      <td>0.291096</td>\n",
              "      <td>0.231434</td>\n",
              "      <td>0.211248</td>\n",
              "      <td>0.180169</td>\n",
              "      <td>0.211466</td>\n",
              "      <td>0.194164</td>\n",
              "      <td>0.226992</td>\n",
              "      <td>0.022128</td>\n",
              "      <td>0.333135</td>\n",
              "      <td>0.211711</td>\n",
              "      <td>0.180691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows  195 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             rating     sentiment  ...        almost        either\n",
              "count  53072.000000  53072.000000  ...  53072.000000  53072.000000\n",
              "mean       3.097490      0.001620  ...      0.039852      0.029846\n",
              "std        1.730509      1.000008  ...      0.211711      0.180691\n",
              "min        1.000000     -1.000000  ...      0.000000      0.000000\n",
              "25%        1.000000     -1.000000  ...      0.000000      0.000000\n",
              "50%        4.000000      1.000000  ...      0.000000      0.000000\n",
              "75%        5.000000      1.000000  ...      0.000000      0.000000\n",
              "max        5.000000      1.000000  ...      4.000000      4.000000\n",
              "\n",
              "[8 rows x 195 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZCHZDUBs9zm",
        "colab_type": "text"
      },
      "source": [
        "## Logistic Regression Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaQBaRA7rMpr",
        "colab_type": "text"
      },
      "source": [
        "Matrix calculations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxU4w8R-qtO_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_numpy_data(data, features, label):\n",
        "    data['constant'] = 1\n",
        "    features = ['constant'] + features\n",
        " \n",
        "    features_df = data[features]     \n",
        "    feature_matrix = features_df.to_numpy() #Convert into a numpy matrix\n",
        "    \n",
        "    label_array = data[label]\n",
        "    label_array = label_array.to_numpy() #Convert into a numpy array\n",
        "\n",
        "    return (feature_matrix, label_array)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t68QdCxfrNYb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_matrix, sentiment = get_numpy_data(data, important_words, 'sentiment')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmrUucXcrf4s",
        "colab_type": "code",
        "outputId": "027df9af-b6c3-41af-e7dc-eebfe08262b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "feature_matrix.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(53072, 194)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IB7zkmDtwgnm",
        "colab_type": "text"
      },
      "source": [
        "#### Predict Probability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKjmobbrw6Ne",
        "colab_type": "text"
      },
      "source": [
        "$ P(y_i = +1 | \\mathbf{x}_i,\\mathbf{w}) = \\frac{1}{1 + \\exp(-Score(\\mathbf{x}_i))} = \\frac{1}{1 + \\exp(-\\mathbf{w}^T h(\\mathbf{x}_i))} $"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBvcDU6zr1NI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_probability(feature_matrix, coefficients): \n",
        "    score = feature_matrix.dot(coefficients)\n",
        "    predictions = 1 / (1 + np.exp(-score))\n",
        "    return predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "re6Y1oiI8XvL",
        "colab_type": "text"
      },
      "source": [
        "#### Compute (log-)likelihood"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uvs0Qa1GxU0Z",
        "colab_type": "text"
      },
      "source": [
        "$ \\ell\\ell(\\mathbf{w}) = \\sum_{i=1}^N \\Big( (\\mathbf{1}[y_i = +1] - 1)\\mathbf{w}^T h(\\mathbf{x}_i) - \\ln\\left(1 + \\exp(-\\mathbf{w}^T h(\\mathbf{x}_i))\\right) \\Big) $\n",
        "\n",
        "$ \\ell\\ell(\\mathbf{w}) = \\sum_{i=1}^N \\Big( (Indicator funtion - 1)Score(\\mathbf{x}_i) - \\ln(1 + \\exp(-Score(\\mathbf{x}_i)) \\Big) $"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4_VqUUusIWc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_log_likelihood(feature_matrix, sentiment, coefficients):\n",
        "    scores = np.dot(feature_matrix, coefficients)\n",
        "    indicator_function = (sentiment==+1)\n",
        "    \n",
        "    ll = np.sum((indicator_function-1)*scores - np.log(1. + np.exp(-scores)))\n",
        "    return ll"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhCoUCyL1C3G",
        "colab_type": "text"
      },
      "source": [
        "#### Gradient Ascent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8iMJtTb1sWb",
        "colab_type": "text"
      },
      "source": [
        "$ w^{(t+1)} = w^{(t)} + \\eta \\frac{d\\ell}{dw} |_{w^{(t)}} $\n",
        "\n",
        "or\n",
        "\n",
        "$ \\mathbf{w}^{(t+1)} = \\mathbf{w}^{(t)} + \\eta \\nabla  \\ell(\\mathbf{w}^{(t)}) $"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xg8hhEzZ100C",
        "colab_type": "text"
      },
      "source": [
        "Where, $  \\frac{d \\ell(\\mathbf{w})}{d\\mathbf{w}_j} = \\sum_{i=1}^N h_j(\\mathbf{x}_i)\\left(\\mathbf{1}[y_i = +1] - P(y_i = +1 | \\mathbf{x}_i, \\mathbf{w})\\right) = \\sum feature * (indicator - predictions) = \\sum feature * error $"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mg915pH_sKuv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def logistic_regression(feature_matrix, sentiment, initial_coefficients, step_size, max_iter):\n",
        "    coefficients = np.array(initial_coefficients) # make sure it's a numpy array\n",
        "    for itr in range(max_iter):\n",
        "        predictions = predict_probability(feature_matrix, coefficients)\n",
        "        indicator = (sentiment==+1)\n",
        "        errors = indicator - predictions\n",
        "\n",
        "        for j in range(len(coefficients)): # loop over each coefficient        \n",
        "            derivative = sum(feature_matrix[:,j] * errors)\n",
        "            coefficients[j] = coefficients[j] + (step_size * derivative)\n",
        "        \n",
        "        #to limit the no. of lines\n",
        "        if itr <= 15 or (itr <= 100 and itr % 10 == 0) or (itr <= 1000 and itr % 100 == 0) or (itr <= 10000 and itr % 1000 == 0) or itr % 10000 == 0:\n",
        "            ll = compute_log_likelihood(feature_matrix, sentiment, coefficients)\n",
        "            print(f\"Iteration {itr}: Log-Likelihood = {ll}\")\n",
        "            \n",
        "    return coefficients"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKsPrnt-FTpP",
        "colab_type": "text"
      },
      "source": [
        "### Fitting the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFYbo9_9sRi3",
        "colab_type": "code",
        "outputId": "881eab68-6ad8-4ff3-81d3-d53a321920a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        }
      },
      "source": [
        "coefficients = logistic_regression(feature_matrix, sentiment, initial_coefficients=np.zeros(feature_matrix.shape[1]),\n",
        "                                   step_size=1e-7, max_iter=301)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 0: Log-Likelihood = -36780.91768478126\n",
            "Iteration 1: Log-Likelihood = -36775.1343471232\n",
            "Iteration 2: Log-Likelihood = -36769.3571356369\n",
            "Iteration 3: Log-Likelihood = -36763.5860323965\n",
            "Iteration 4: Log-Likelihood = -36757.82101961526\n",
            "Iteration 5: Log-Likelihood = -36752.06207964397\n",
            "Iteration 6: Log-Likelihood = -36746.30919496959\n",
            "Iteration 7: Log-Likelihood = -36740.562348213745\n",
            "Iteration 8: Log-Likelihood = -36734.82152213134\n",
            "Iteration 9: Log-Likelihood = -36729.08669960911\n",
            "Iteration 10: Log-Likelihood = -36723.357863664314\n",
            "Iteration 11: Log-Likelihood = -36717.634997443216\n",
            "Iteration 12: Log-Likelihood = -36711.91808421987\n",
            "Iteration 13: Log-Likelihood = -36706.20710739464\n",
            "Iteration 14: Log-Likelihood = -36700.502050493\n",
            "Iteration 15: Log-Likelihood = -36694.8028971641\n",
            "Iteration 20: Log-Likelihood = -36666.39512032845\n",
            "Iteration 30: Log-Likelihood = -36610.01327118031\n",
            "Iteration 40: Log-Likelihood = -36554.19728365376\n",
            "Iteration 50: Log-Likelihood = -36498.93316099373\n",
            "Iteration 60: Log-Likelihood = -36444.20783913862\n",
            "Iteration 70: Log-Likelihood = -36390.009094487075\n",
            "Iteration 80: Log-Likelihood = -36336.3254614401\n",
            "Iteration 90: Log-Likelihood = -36283.14615870863\n",
            "Iteration 100: Log-Likelihood = -36230.46102346926\n",
            "Iteration 200: Log-Likelihood = -35728.89418769386\n",
            "Iteration 300: Log-Likelihood = -35268.51212682766\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_MIniogDGCQ",
        "colab_type": "text"
      },
      "source": [
        "We see Log-Likelihood is Increasing!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMxTAMFLsc8-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Computing predicted scores\n",
        "scores = np.dot(feature_matrix, coefficients)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iy8anqHT9wuz",
        "colab_type": "text"
      },
      "source": [
        "### Making predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0kdqbcOee6W",
        "colab_type": "text"
      },
      "source": [
        "$\n",
        "\\hat{y}_i = \n",
        "\\left\\{\n",
        "\\begin{array}{ll}\n",
        "      +1 & \\mathbf{x}_i^T\\mathbf{w} \\gt 0 \\\\\n",
        "      -1 & \\mathbf{x}_i^T\\mathbf{w} \\leq 0 \\\\\n",
        "\\end{array} \n",
        "\\right.\n",
        "$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOjchDHB449q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def class_predictions(score):\n",
        "    if score > 0:\n",
        "        return 1\n",
        "    else:\n",
        "        return -1\n",
        "\n",
        "predictions_func = np.vectorize(class_predictions)\n",
        "predictions = predictions_func(scores)\n",
        "# print(predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaSpLwqOtQVz",
        "colab_type": "code",
        "outputId": "fb9d7484-e199-42e2-cb56-23768854bc16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "print(\"Positive Predictions:\", predictions[predictions == 1].sum())\n",
        "print(\"Negative Predictions:\", predictions[predictions == -1].sum()*-1)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive Predictions: 25126\n",
            "Negative Predictions: 27946\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gg-ELETS9q8R",
        "colab_type": "text"
      },
      "source": [
        "### Evaluating the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aF8tVPHWtSdP",
        "colab_type": "code",
        "outputId": "80ebe8b8-8ad2-4ffd-a0ef-201a769b2699",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "num_correct =  (sentiment == predictions).sum()\n",
        "accuracy = (num_correct) / len(data)\n",
        "\n",
        "print('Reviews   correctly classified =', num_correct)\n",
        "print('Reviews incorrectly classified =', len(data) - num_correct)\n",
        "print('Reviews total                  =', len(data))\n",
        "print('---------------------------------------')\n",
        "print('Accuracy:',   accuracy)\n",
        "print('   Error:', 1-accuracy)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reviews   correctly classified = 39903\n",
            "Reviews incorrectly classified = 13169\n",
            "Reviews total                  = 53072\n",
            "---------------------------------------\n",
            "Accuracy: 0.7518653904130238\n",
            "   Error: 0.2481346095869762\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvUbuleC6cJt",
        "colab_type": "code",
        "outputId": "c1c797de-256e-4319-9b4b-877f4b1c51d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        }
      },
      "source": [
        "print(\"Intercept:\", coefficients[0])\n",
        "coef_df = pd.DataFrame(zip(important_words, coefficients[1:]), columns=(\"Words\", \"Coefficients\"))\n",
        "coef_df.sort_values('Coefficients').set_index('Words')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Intercept: 0.005162201572858296\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Coefficients</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Words</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>would</th>\n",
              "      <td>-0.053860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>product</th>\n",
              "      <td>-0.041511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>money</th>\n",
              "      <td>-0.038982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>work</th>\n",
              "      <td>-0.033070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>even</th>\n",
              "      <td>-0.030051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>loves</th>\n",
              "      <td>0.044976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>little</th>\n",
              "      <td>0.045436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>easy</th>\n",
              "      <td>0.064795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>love</th>\n",
              "      <td>0.065891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>great</th>\n",
              "      <td>0.066546</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>193 rows  1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         Coefficients\n",
              "Words                \n",
              "would       -0.053860\n",
              "product     -0.041511\n",
              "money       -0.038982\n",
              "work        -0.033070\n",
              "even        -0.030051\n",
              "...               ...\n",
              "loves        0.044976\n",
              "little       0.045436\n",
              "easy         0.064795\n",
              "love         0.065891\n",
              "great        0.066546\n",
              "\n",
              "[193 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngd2XzVRmqC4",
        "colab_type": "text"
      },
      "source": [
        "## Logistic Regression with L2 Regularization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tjg3DYMrjDzU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "with open('train-idx.json', 'r') as f:\n",
        "    train_idx = json.load(f)\n",
        "with open('validation-idx.json', 'r') as f:\n",
        "    validation_idx = json.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2eDYBqzjHyE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = data.iloc[train_idx]\n",
        "validation_data = data.iloc[validation_idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PujySebGnNei",
        "colab_type": "code",
        "outputId": "7297821e-8530-452f-bdb4-77ff6ce0fd14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(validation_data), len(train_data)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10711, 42361)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2w10lBMmroI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_matrix_train, sentiment_train = get_numpy_data(train_data, important_words, 'sentiment')\n",
        "feature_matrix_valid, sentiment_valid = get_numpy_data(validation_data, important_words, 'sentiment')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzKivuccnnJf",
        "colab_type": "text"
      },
      "source": [
        "### L2 penalty"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXsHwsgPoOip",
        "colab_type": "text"
      },
      "source": [
        "#### Compute (log-)likelihood with L2 penality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Cv1IioioH2W",
        "colab_type": "text"
      },
      "source": [
        "$\\ell\\ell(\\mathbf{w}) = \\sum_{i=1}^N \\Big( (\\mathbf{1}[y_i = +1] - 1)\\mathbf{w}^T h(\\mathbf{x}_i) - \\ln\\left(1 + \\exp(-\\mathbf{w}^T h(\\mathbf{x}_i))\\right) \\Big) \\color{red}{-\\lambda\\|\\mathbf{w}\\|_2^2} $\n",
        "\n",
        "$ \\ell\\ell(\\mathbf{w}) = \\sum_{i=1}^N \\Big( (Indicator funtion - 1)Score(\\mathbf{x}_i) - \\ln(1 + \\exp(-Score(\\mathbf{x}_i)) \\Big) \\color{red}{-\\lambda\\|\\mathbf{w}\\|_2^2}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHVWAVkAngXI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_log_likelihood_with_L2(feature_matrix, sentiment, coefficients, l2_penalty):\n",
        "    indicator_function = (sentiment==+1)\n",
        "    scores = np.dot(feature_matrix, coefficients)\n",
        "    \n",
        "    ll = np.sum((indicator_function-1)*scores - np.log(1. + np.exp(-scores))) - l2_penalty*np.sum(coefficients[1:]**2)    \n",
        "    return ll"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-81fAVgpdAn",
        "colab_type": "text"
      },
      "source": [
        "#### Gradient Ascent with L2 penality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRhyZ-LOpoMn",
        "colab_type": "text"
      },
      "source": [
        "The only change we make is:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLCN6xmwnpRi",
        "colab_type": "text"
      },
      "source": [
        "$\n",
        "\\frac{\\partial\\ell}{\\partial w_j} = \\sum_{i=1}^N h_j(\\mathbf{x}_i)\\left(\\mathbf{1}[y_i = +1] - P(y_i = +1 | \\mathbf{x}_i, \\mathbf{w})\\right) \\color{red}{-2\\lambda w_j }\n",
        "$\n",
        "\n",
        "$ = \\sum feature * (indicator - predictions) \\color{red}{-2\\lambda w_j} = \\sum (feature * error) \\color{red}{-2\\lambda w_j} $"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UraIxc61nsUZ",
        "colab_type": "text"
      },
      "source": [
        "We do not apply the L2 penalty ($\n",
        " \\color{red}{-2\\lambda w_j }\n",
        "$) on the intercept. A large intercept does not necessarily indicate overfitting because the intercept is not associated with any particular feature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guFrSH1hpyhK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def feature_derivative_with_L2(errors, feature, coefficient, l2_penalty, feature_is_constant): \n",
        "    derivative = sum(feature * errors)\n",
        "\n",
        "    # add L2 penalty term for any feature that isn't the intercept\n",
        "    if not feature_is_constant: \n",
        "        derivative = derivative - (2 * l2_penalty * coefficient)\n",
        "        \n",
        "    return derivative"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-TEpU7gpKDP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def logistic_regression_with_L2(feature_matrix, sentiment, initial_coefficients, step_size, l2_penalty, max_iter):\n",
        "    coefficients = np.array(initial_coefficients) # make sure it's a numpy array\n",
        "    for itr in range(max_iter):        \n",
        "        predictions = predict_probability(feature_matrix, coefficients)\n",
        "        indicator = (sentiment==+1)\n",
        "        errors = indicator - predictions\n",
        "        \n",
        "        for j in range(len(coefficients)): # loop over each coefficient\n",
        "            is_intercept = (j == 0)\n",
        "            derivative = feature_derivative_with_L2(errors, feature_matrix[:,j], coefficients[j], l2_penalty, is_intercept)\n",
        "            coefficients[j] = coefficients[j] + (step_size * derivative)\n",
        "        \n",
        "        #to limit the no. of lines\n",
        "        if itr <= 15 or (itr <= 100 and itr % 10 == 0) or (itr <= 1000 and itr % 100 == 0) or (itr <= 10000 and itr % 1000 == 0) or itr % 10000 == 0:\n",
        "            ll =  compute_log_likelihood_with_L2(feature_matrix, sentiment, coefficients, l2_penalty)\n",
        "            print(f\"Iteration {itr}: Log-Likelihood = {ll}\")\n",
        "\n",
        "    return coefficients"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot3QhJ_erqXi",
        "colab_type": "text"
      },
      "source": [
        "### Fitting the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JflLM1iwbMj",
        "colab_type": "text"
      },
      "source": [
        "We try with multiple L2 penalty"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVoHcKImrpog",
        "colab_type": "code",
        "outputId": "872c061b-ce8f-4058-fb7a-824ebcf07427",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "# With L2 = 0, i.e without penalty\n",
        "coefficients_0_penalty = logistic_regression_with_L2(feature_matrix_train, sentiment_train,\n",
        "                                                     initial_coefficients=np.zeros(194),\n",
        "                                                     step_size=5e-6, l2_penalty=0, max_iter=501)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 0: Log-Likelihood = -29179.39138302689\n",
            "Iteration 1: Log-Likelihood = -29003.712590466093\n",
            "Iteration 2: Log-Likelihood = -28834.661872878623\n",
            "Iteration 3: Log-Likelihood = -28671.707815069705\n",
            "Iteration 4: Log-Likelihood = -28514.430781982304\n",
            "Iteration 5: Log-Likelihood = -28362.48344664838\n",
            "Iteration 6: Log-Likelihood = -28215.567131220505\n",
            "Iteration 7: Log-Likelihood = -28073.41743783136\n",
            "Iteration 8: Log-Likelihood = -27935.795363960744\n",
            "Iteration 9: Log-Likelihood = -27802.48168669038\n",
            "Iteration 10: Log-Likelihood = -27673.273314842878\n",
            "Iteration 11: Log-Likelihood = -27547.980836558698\n",
            "Iteration 12: Log-Likelihood = -27426.426799766796\n",
            "Iteration 13: Log-Likelihood = -27308.444447278995\n",
            "Iteration 14: Log-Likelihood = -27193.876738760107\n",
            "Iteration 15: Log-Likelihood = -27082.575558309214\n",
            "Iteration 20: Log-Likelihood = -26570.430599383417\n",
            "Iteration 30: Log-Likelihood = -25725.487423891307\n",
            "Iteration 40: Log-Likelihood = -25055.533269103304\n",
            "Iteration 50: Log-Likelihood = -24509.635900260408\n",
            "Iteration 60: Log-Likelihood = -24054.979060830763\n",
            "Iteration 70: Log-Likelihood = -23669.516408482497\n",
            "Iteration 80: Log-Likelihood = -23337.891676277064\n",
            "Iteration 90: Log-Likelihood = -23049.070660206624\n",
            "Iteration 100: Log-Likelihood = -22794.90974920854\n",
            "Iteration 200: Log-Likelihood = -21283.295273529307\n",
            "Iteration 300: Log-Likelihood = -20570.974854729528\n",
            "Iteration 400: Log-Likelihood = -20152.21466944124\n",
            "Iteration 500: Log-Likelihood = -19876.623334098615\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I82P8fRGwkZy",
        "colab_type": "code",
        "outputId": "7dfa687a-9497-4b23-f23e-f7e44ac4eb80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "# With L2 = 4\n",
        "coefficients_4_penalty = logistic_regression_with_L2(feature_matrix_train, sentiment_train,\n",
        "                                                      initial_coefficients=np.zeros(194),\n",
        "                                                      step_size=5e-6, l2_penalty=4, max_iter=501)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 0: Log-Likelihood = -29179.395081753617\n",
            "Iteration 1: Log-Likelihood = -29003.73417180492\n",
            "Iteration 2: Log-Likelihood = -28834.714418581865\n",
            "Iteration 3: Log-Likelihood = -28671.803450678704\n",
            "Iteration 4: Log-Likelihood = -28514.580779565153\n",
            "Iteration 5: Log-Likelihood = -28362.698303173485\n",
            "Iteration 6: Log-Likelihood = -28215.856632589206\n",
            "Iteration 7: Log-Likelihood = -28073.790713931412\n",
            "Iteration 8: Log-Likelihood = -27936.260937616433\n",
            "Iteration 9: Log-Likelihood = -27803.04751805441\n",
            "Iteration 10: Log-Likelihood = -27673.946842074038\n",
            "Iteration 11: Log-Likelihood = -27548.769013273926\n",
            "Iteration 12: Log-Likelihood = -27427.336129584306\n",
            "Iteration 13: Log-Likelihood = -27309.481015690344\n",
            "Iteration 14: Log-Likelihood = -27195.046242533623\n",
            "Iteration 15: Log-Likelihood = -27083.883332610094\n",
            "Iteration 20: Log-Likelihood = -26572.498743920918\n",
            "Iteration 30: Log-Likelihood = -25729.32604153253\n",
            "Iteration 40: Log-Likelihood = -25061.342458006082\n",
            "Iteration 50: Log-Likelihood = -24517.520919819428\n",
            "Iteration 60: Log-Likelihood = -24064.99093938855\n",
            "Iteration 70: Log-Likelihood = -23681.67373669373\n",
            "Iteration 80: Log-Likelihood = -23352.192987412298\n",
            "Iteration 90: Log-Likelihood = -23065.501801662514\n",
            "Iteration 100: Log-Likelihood = -22813.448445799357\n",
            "Iteration 200: Log-Likelihood = -21321.141647938977\n",
            "Iteration 300: Log-Likelihood = -20624.986344387962\n",
            "Iteration 400: Log-Likelihood = -20219.920488449716\n",
            "Iteration 500: Log-Likelihood = -19956.113417765006\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deM6BfKbwm-9",
        "colab_type": "code",
        "outputId": "3140e967-53a5-4a68-9b7e-0f40441c3de6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "# With L2 = 10\n",
        "coefficients_10_penalty = logistic_regression_with_L2(feature_matrix_train, sentiment_train,\n",
        "                                                      initial_coefficients=np.zeros(194),\n",
        "                                                      step_size=5e-6, l2_penalty=10, max_iter=501)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 0: Log-Likelihood = -29179.4006298437\n",
            "Iteration 1: Log-Likelihood = -29003.766541629113\n",
            "Iteration 2: Log-Likelihood = -28834.793226544734\n",
            "Iteration 3: Log-Likelihood = -28671.94687528158\n",
            "Iteration 4: Log-Likelihood = -28514.805715892686\n",
            "Iteration 5: Log-Likelihood = -28363.02048078528\n",
            "Iteration 6: Log-Likelihood = -28216.290711863126\n",
            "Iteration 7: Log-Likelihood = -28074.35036890762\n",
            "Iteration 8: Log-Likelihood = -27936.95892965964\n",
            "Iteration 9: Log-Likelihood = -27803.895762654603\n",
            "Iteration 10: Log-Likelihood = -27674.95647005435\n",
            "Iteration 11: Log-Likelihood = -27549.95042714027\n",
            "Iteration 12: Log-Likelihood = -27428.699055494057\n",
            "Iteration 13: Log-Likelihood = -27311.034551398705\n",
            "Iteration 14: Log-Likelihood = -27196.79890162302\n",
            "Iteration 15: Log-Likelihood = -27085.843085282024\n",
            "Iteration 20: Log-Likelihood = -26575.5969750566\n",
            "Iteration 30: Log-Likelihood = -25735.073046084293\n",
            "Iteration 40: Log-Likelihood = -25070.03447305897\n",
            "Iteration 50: Log-Likelihood = -24529.31188025413\n",
            "Iteration 60: Log-Likelihood = -24079.953495715956\n",
            "Iteration 70: Log-Likelihood = -23699.831991862666\n",
            "Iteration 80: Log-Likelihood = -23373.541087473324\n",
            "Iteration 90: Log-Likelihood = -23090.015000545227\n",
            "Iteration 100: Log-Likelihood = -22841.08995135216\n",
            "Iteration 200: Log-Likelihood = -21377.255953281892\n",
            "Iteration 300: Log-Likelihood = -20704.639954281603\n",
            "Iteration 400: Log-Likelihood = -20319.256853074035\n",
            "Iteration 500: Log-Likelihood = -20072.163217214034\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3wtKFPAwqfJ",
        "colab_type": "code",
        "outputId": "3a8610d1-3bc2-4efb-d943-9ee9a1b7873a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "# With L2 = 1e2\n",
        "coefficients_1e2_penalty = logistic_regression_with_L2(feature_matrix_train, sentiment_train,\n",
        "                                                       initial_coefficients=np.zeros(194),\n",
        "                                                       step_size=5e-6, l2_penalty=1e2, max_iter=501)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 0: Log-Likelihood = -29179.483851195015\n",
            "Iteration 1: Log-Likelihood = -29004.25177456867\n",
            "Iteration 2: Log-Likelihood = -28835.973821901112\n",
            "Iteration 3: Log-Likelihood = -28674.094100830727\n",
            "Iteration 4: Log-Likelihood = -28518.17112931624\n",
            "Iteration 5: Log-Likelihood = -28367.83774653677\n",
            "Iteration 6: Log-Likelihood = -28222.777089394982\n",
            "Iteration 7: Log-Likelihood = -28082.70799391817\n",
            "Iteration 8: Log-Likelihood = -27947.3759536754\n",
            "Iteration 9: Log-Likelihood = -27816.547386152713\n",
            "Iteration 10: Log-Likelihood = -27690.005888496114\n",
            "Iteration 11: Log-Likelihood = -27567.549701255328\n",
            "Iteration 12: Log-Likelihood = -27448.989913268753\n",
            "Iteration 13: Log-Likelihood = -27334.14912742369\n",
            "Iteration 14: Log-Likelihood = -27222.860418630866\n",
            "Iteration 15: Log-Likelihood = -27114.966482291587\n",
            "Iteration 20: Log-Likelihood = -26621.50201299239\n",
            "Iteration 30: Log-Likelihood = -25819.72803950465\n",
            "Iteration 40: Log-Likelihood = -25197.34035500628\n",
            "Iteration 50: Log-Likelihood = -24701.03698195158\n",
            "Iteration 60: Log-Likelihood = -24296.663785802226\n",
            "Iteration 70: Log-Likelihood = -23961.388423157972\n",
            "Iteration 80: Log-Likelihood = -23679.380888533116\n",
            "Iteration 90: Log-Likelihood = -23439.318242668513\n",
            "Iteration 100: Log-Likelihood = -23232.881920184136\n",
            "Iteration 200: Log-Likelihood = -22133.50726528031\n",
            "Iteration 300: Log-Likelihood = -21730.039574878283\n",
            "Iteration 400: Log-Likelihood = -21545.87572144833\n",
            "Iteration 500: Log-Likelihood = -21451.955513895395\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMx2YusgwtQ0",
        "colab_type": "code",
        "outputId": "4f65f6c8-d825-468c-9859-c0e4fcc2e1f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "# With L2 = 1e3\n",
        "coefficients_1e3_penalty = logistic_regression_with_L2(feature_matrix_train, sentiment_train,\n",
        "                                                       initial_coefficients=np.zeros(194),\n",
        "                                                       step_size=5e-6, l2_penalty=1e3, max_iter=501)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 0: Log-Likelihood = -29180.31606470814\n",
            "Iteration 1: Log-Likelihood = -29009.071761117153\n",
            "Iteration 2: Log-Likelihood = -28847.62378912284\n",
            "Iteration 3: Log-Likelihood = -28695.144393968003\n",
            "Iteration 4: Log-Likelihood = -28550.950607434377\n",
            "Iteration 5: Log-Likelihood = -28414.4577112854\n",
            "Iteration 6: Log-Likelihood = -28285.151243752676\n",
            "Iteration 7: Log-Likelihood = -28162.56976043934\n",
            "Iteration 8: Log-Likelihood = -28046.293877443597\n",
            "Iteration 9: Log-Likelihood = -27935.939028997054\n",
            "Iteration 10: Log-Likelihood = -27831.15045501687\n",
            "Iteration 11: Log-Likelihood = -27731.599552598025\n",
            "Iteration 12: Log-Likelihood = -27636.98108219489\n",
            "Iteration 13: Log-Likelihood = -27547.010926701918\n",
            "Iteration 14: Log-Likelihood = -27461.42422294827\n",
            "Iteration 15: Log-Likelihood = -27379.97375625301\n",
            "Iteration 20: Log-Likelihood = -27027.182083171854\n",
            "Iteration 30: Log-Likelihood = -26527.22737266983\n",
            "Iteration 40: Log-Likelihood = -26206.590487651112\n",
            "Iteration 50: Log-Likelihood = -25995.96903148361\n",
            "Iteration 60: Log-Likelihood = -25854.957102843353\n",
            "Iteration 70: Log-Likelihood = -25759.08109950455\n",
            "Iteration 80: Log-Likelihood = -25693.056880137865\n",
            "Iteration 90: Log-Likelihood = -25647.09929349318\n",
            "Iteration 100: Log-Likelihood = -25614.814687051265\n",
            "Iteration 200: Log-Likelihood = -25536.209989186347\n",
            "Iteration 300: Log-Likelihood = -25532.576912204662\n",
            "Iteration 400: Log-Likelihood = -25532.3554376499\n",
            "Iteration 500: Log-Likelihood = -25532.339700486227\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUqSRMTSwwsE",
        "colab_type": "code",
        "outputId": "6045990a-d2fb-4978-c904-c923a4448803",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "# With L2 = 1e5\n",
        "coefficients_1e5_penalty = logistic_regression_with_L2(feature_matrix_train, sentiment_train,\n",
        "                                                       initial_coefficients=np.zeros(194),\n",
        "                                                       step_size=5e-6, l2_penalty=1e5, max_iter=501)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 0: Log-Likelihood = -29271.85955115189\n",
            "Iteration 1: Log-Likelihood = -29271.71006588519\n",
            "Iteration 2: Log-Likelihood = -29271.65738832722\n",
            "Iteration 3: Log-Likelihood = -29271.61189922826\n",
            "Iteration 4: Log-Likelihood = -29271.57079974803\n",
            "Iteration 5: Log-Likelihood = -29271.533585046815\n",
            "Iteration 6: Log-Likelihood = -29271.499884403343\n",
            "Iteration 7: Log-Likelihood = -29271.469365844292\n",
            "Iteration 8: Log-Likelihood = -29271.441728903956\n",
            "Iteration 9: Log-Likelihood = -29271.416701494072\n",
            "Iteration 10: Log-Likelihood = -29271.394037217673\n",
            "Iteration 11: Log-Likelihood = -29271.37351294304\n",
            "Iteration 12: Log-Likelihood = -29271.354926606935\n",
            "Iteration 13: Log-Likelihood = -29271.33809522536\n",
            "Iteration 14: Log-Likelihood = -29271.322853092006\n",
            "Iteration 15: Log-Likelihood = -29271.30905014689\n",
            "Iteration 20: Log-Likelihood = -29271.257291497048\n",
            "Iteration 30: Log-Likelihood = -29271.20657204836\n",
            "Iteration 40: Log-Likelihood = -29271.18775997432\n",
            "Iteration 50: Log-Likelihood = -29271.180782472904\n",
            "Iteration 60: Log-Likelihood = -29271.178194474804\n",
            "Iteration 70: Log-Likelihood = -29271.17723456932\n",
            "Iteration 80: Log-Likelihood = -29271.176878533806\n",
            "Iteration 90: Log-Likelihood = -29271.176746477733\n",
            "Iteration 100: Log-Likelihood = -29271.176697497194\n",
            "Iteration 200: Log-Likelihood = -29271.17666862016\n",
            "Iteration 300: Log-Likelihood = -29271.17666861874\n",
            "Iteration 400: Log-Likelihood = -29271.17666861874\n",
            "Iteration 500: Log-Likelihood = -29271.17666861874\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnfILeBsuo4A",
        "colab_type": "text"
      },
      "source": [
        "#### Measuring Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G876IRcwrujw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_classification_accuracy(feature_matrix, sentiment, coefficients):\n",
        "    scores = np.dot(feature_matrix, coefficients)\n",
        "    \n",
        "    #making predictions\n",
        "    apply_threshold = np.vectorize(lambda x: 1. if x > 0  else -1.)\n",
        "    predictions = apply_threshold(scores)\n",
        "    \n",
        "    num_correct = (predictions == sentiment).sum()\n",
        "    accuracy = num_correct / len(feature_matrix)    \n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpxnqaA3xKYF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_accuracy = {}\n",
        "train_accuracy[0]   = get_classification_accuracy(feature_matrix_train, sentiment_train, coefficients_0_penalty)\n",
        "train_accuracy[4]   = get_classification_accuracy(feature_matrix_train, sentiment_train, coefficients_4_penalty)\n",
        "train_accuracy[10]  = get_classification_accuracy(feature_matrix_train, sentiment_train, coefficients_10_penalty)\n",
        "train_accuracy[1e2] = get_classification_accuracy(feature_matrix_train, sentiment_train, coefficients_1e2_penalty)\n",
        "train_accuracy[1e3] = get_classification_accuracy(feature_matrix_train, sentiment_train, coefficients_1e3_penalty)\n",
        "train_accuracy[1e5] = get_classification_accuracy(feature_matrix_train, sentiment_train, coefficients_1e5_penalty)\n",
        "\n",
        "validation_accuracy = {}\n",
        "validation_accuracy[0]   = get_classification_accuracy(feature_matrix_valid, sentiment_valid, coefficients_0_penalty)\n",
        "validation_accuracy[4]   = get_classification_accuracy(feature_matrix_valid, sentiment_valid, coefficients_4_penalty)\n",
        "validation_accuracy[10]  = get_classification_accuracy(feature_matrix_valid, sentiment_valid, coefficients_10_penalty)\n",
        "validation_accuracy[1e2] = get_classification_accuracy(feature_matrix_valid, sentiment_valid, coefficients_1e2_penalty)\n",
        "validation_accuracy[1e3] = get_classification_accuracy(feature_matrix_valid, sentiment_valid, coefficients_1e3_penalty)\n",
        "validation_accuracy[1e5] = get_classification_accuracy(feature_matrix_valid, sentiment_valid, coefficients_1e5_penalty)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95WZOMpIx1mq",
        "colab_type": "code",
        "outputId": "a4f3cb7d-7a5d-48c6-cfd9-2a3704631db1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        }
      },
      "source": [
        "for key in sorted(validation_accuracy.keys()):\n",
        "    print(f\"L2 penalty = {key}\")\n",
        "    print(f\"train accuracy = {train_accuracy[key]}, validation_accuracy = {validation_accuracy[key]}\")\n",
        "    print(\"--------------------------------------------------------------------------------\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "L2 penalty = 0\n",
            "train accuracy = 0.7851561577866434, validation_accuracy = 0.781439641490057\n",
            "--------------------------------------------------------------------------------\n",
            "L2 penalty = 4\n",
            "train accuracy = 0.7851089445480512, validation_accuracy = 0.7815330034543927\n",
            "--------------------------------------------------------------------------------\n",
            "L2 penalty = 10\n",
            "train accuracy = 0.7849909114515711, validation_accuracy = 0.7817197273830642\n",
            "--------------------------------------------------------------------------------\n",
            "L2 penalty = 100.0\n",
            "train accuracy = 0.7839758268218409, validation_accuracy = 0.781066193632714\n",
            "--------------------------------------------------------------------------------\n",
            "L2 penalty = 1000.0\n",
            "train accuracy = 0.7758551497839994, validation_accuracy = 0.7713565493417982\n",
            "--------------------------------------------------------------------------------\n",
            "L2 penalty = 100000.0\n",
            "train accuracy = 0.6803663747314747, validation_accuracy = 0.667818130893474\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}